#######################################################################################################################
from copy import deepcopy
from itertools import combinations, chain, permutations
from math import sqrt, log
from scipy.stats import norm, chi2
from numpy import log as ln
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import warnings
#######################################################################################################################

def fisherZ(correlation_matrix, X, Y, condition_set, sample_size):
    "Perform an independence test using Fisher-Z's test and output the p-value of the test"
    var = list((X, Y) + condition_set)
    sub_corr_matrix = correlation_matrix[np.ix_(var, var)]
    inv = np.linalg.inv(sub_corr_matrix)
    r = -inv[0, 1] / sqrt(inv[0, 0] * inv[1, 1])
    Z = 0.5 * log((1 + r) / (1 - r))
    X = sqrt(sample_size - len(condition_set) - 3) * abs(Z)
    p = 1 - norm.cdf(abs(X))
    return p

#######################################################################################################################

def chisq(data, X, Y, conditioning_set, G_sq=False):
    "Perform an independence test using chi-square test and output the p-value of the test"
    # Step 1: Subset the data
    categories_list = [np.unique(data[:, i]) for i in list(conditioning_set)]  # Obtain the categories of each variable in conditioning_set
    value_config_list = cartesian_product(categories_list)  # Obtain all the possible value configurations of the conditioning_set (e.g., [[]] if categories_list == [])

    max_categories = int(np.max(data)) + 1  # Used to fix the size of the contingency table (before applying Fienberg's method)

    sum_of_chi_square = 0  # initialize a zero chi_square statistic
    sum_of_df = 0  # initialize a zero degree of freedom

    def recursive_and(L):
        "A helper function for subsetting the data using the conditions in L of the form [(variable, value),...]"
        if len(L) == 0:
            return data
        else:
            condition = data[:, L[0][0]] == L[0][1]
            i = 1
            while i < len(L):
                new_conjunct = data[:, L[i][0]] == L[i][1]
                condition = new_conjunct & condition
                i += 1
            return data[condition]

    for value_config in range(len(value_config_list)):
        L = list(zip(conditioning_set, value_config_list[value_config]))
        sub_data = recursive_and(L)[:, [X, Y]]  # obtain the subset dataset (containing only the X, Y columns) with only rows specifed in value_config

        # Step 2: Generate contingency table (applying Fienberg's method)
        def make_ctable(D, cat_size):
            x = np.array(D[:, 0], dtype=np.dtype(int))
            y = np.array(D[:, 1], dtype=np.dtype(int))
            bin_count = np.bincount(cat_size * x + y)  # Perform linear transformation to obtain frequencies
            diff = (cat_size ** 2) - len(bin_count)
            if diff > 0:  # The number of cells generated by bin_count can possibly be less than cat_size**2
                bin_count = np.concatenate((bin_count, np.zeros(diff)))  # In that case, we concatenate some zeros to fit cat_size**2
            ctable = bin_count.reshape(cat_size, cat_size)
            ctable = ctable[~np.all(ctable == 0, axis=1)]  # Remove rows consisted entirely of zeros
            ctable = ctable[:, ~np.all(ctable == 0, axis=0)]  # Remove columns consisted entirely of zeros
            return ctable

        ctable = make_ctable(sub_data, max_categories)

        # Step 3: Calculate chi-square statistic and degree of freedom from the contingency table
        row_sum = np.sum(ctable, axis=1)
        col_sum = np.sum(ctable, axis=0)
        expected = np.outer(row_sum, col_sum) / sub_data.shape[0]
        if G_sq == False:
            chi_sq_stat = np.sum(((ctable - expected) ** 2) / expected)
        else:
            div = np.divide(ctable, expected)
            div[div == 0] = 1  # It guarantees that taking natural log in the next step won't cause any error
            chi_sq_stat = 2 * np.sum(ctable * np.log(div))
        df = (ctable.shape[0] - 1) * (ctable.shape[1] - 1)

        sum_of_chi_square += chi_sq_stat
        sum_of_df += df

    # Step 4: Compute p-value from chi-square CDF
    if sum_of_df == 0:
        return 1
    else:
        return chi2.sf(sum_of_chi_square, sum_of_df)

#######################################################################################################################

def appendValue(array, i, j, value):
    "Append value to the list at array[i, j]"
    if array[i, j] == None:
        array[i, j] = [value]
    else:
        array[i, j].append(value)

#######################################################################################################################

def powerset(L):
    "Return the powerset of L (list)"
    s = list(L)
    return list(chain.from_iterable(combinations(s, r) for r in range(len(s) + 1)))

#######################################################################################################################

def cartesian_product(lists):
    "Return the Cartesian product of lists (List of lists)"
    result = [[]]
    for pool in lists:
        result = [x + [y] for x in result for y in pool]
    return result

#######################################################################################################################

def listUnion(L1, L2):
    "Return the union of L1 and L2 (lists)"
    return list(set(L1 + L2))

#######################################################################################################################

def listIntersection(L1, L2):
    "Return the intersection of L1 and L2 (lists)"
    return list(set(L1) & set(L2))

#######################################################################################################################

def listMinus(L1, L2):
    "Return a list of members in L1 (list) that are in L2 (list)"
    return list(set(L1) - set(L2))

#######################################################################################################################

def sortDictAscending(dict, descending=False):
    "Sort dict (dictionary) by its value in ascending order"
    dict_list = sorted(dict.items(), key=lambda x: x[1], reverse=descending)
    return {dict_list[i][0]: dict_list[i][1] for i in range(len(dict_list))}

#######################################################################################################################

def npIgnoreNan(ndarray):
    "Replace all nan entries as blank entries"
    Output = ndarray.astype(str)
    Output[Output == 'nan'] = ''
    return Output

#######################################################################################################################

def getParents(adjmat, i):
    "Obtain the parents of node i in the adjacency matrix adjmat"
    parents = [j for j in range(len(adjmat)) if adjmat[i, j] == 0 and adjmat[j, i] == 1]
    parents.sort()
    return tuple(parents)

#######################################################################################################################

def createBICDict(no_of_nodes):
    """A dictionary is created for storing BIC scores. Note that this function should only be run a single time for
    a dataset (irrespective to the number of DAGs that you are going to consider)"""
    BIC_dict = {}
    for i in range(no_of_nodes):
        BIC_dict[i]={}
    return BIC_dict

#######################################################################################################################

def BIC_graph(adjmat, BIC_dict, cov_matrix, sample_size, penalty=1):
    """ Compute the Bayesian Information Criterion (BIC) score of a DAG (represented by its adjacency matrix adjmat)
    from the covariance matrix cov_matrix. BIC_dict has to be initialized first for computation of the BIC of each node.
    :param adjmat: adjacency matrix (numpy 2darray)
    :param BIC_dict: dictionary needed to be initialized first by createBICDict
    :param cov_matrix: covariance matrix from the data (numpy 2darray)
    :param sample_size: sample size of the data (int)
    :param penalty: penalty discount (int)
    :return: BIC score the DAG (float)
    """
    def BIC_node(adjmat, Y, BIC_dict, cov_matrix, sample_size, penalty):
        "Obtain the BIC of the node Y and update the BIC_dict accordingly"
        parents = getParents(adjmat, Y)
        if parents in BIC_dict[Y].keys():
            return BIC_dict[Y][parents]
        else:
            cov_XX = cov_matrix[np.ix_(parents, parents)]
            cov_XY = cov_matrix[np.ix_(parents, (Y,))]
            cov = cov_matrix[np.ix_((Y,) + parents, (Y,) + parents)]
            b = np.matmul(np.linalg.inv(cov_XX), cov_XY)
            b_star = np.concatenate((np.array([[1]]), -b))
            var_rY = float(np.matmul(np.matmul(b_star.transpose(), cov), b_star))
            k = len(parents)
            lambda_term = penalty * ln(sample_size)
            BIC = (-sample_size * ln(var_rY)) - (k * lambda_term)
            BIC_dict[Y][parents] = BIC
            return BIC

    score = 0
    for Y in range(len(adjmat)):
        score += BIC_node(adjmat, Y, BIC_dict, cov_matrix, sample_size, penalty)
    return score

#######################################################################################################################